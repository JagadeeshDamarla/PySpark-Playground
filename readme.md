## ðŸŽ¯ Purpose
- The purpose of this repository is to practise mutliple scenarios using pyspark and cracking databrick pyspark certification
---

## Current Folders
- EDA 
   - Has a overview of functions/methods that we use in spark to manipulate/transform the dataframes
- Multiple File Formats
   - Has code to read files of multiple data formats

## Future Additions
- Working with multiple files
   - Has the code to tackle datasets with multiple tables predominantly focussing on the joins and their implications
- Streaming solution
   - As spark offers good streaming libraries, this folder contains how we handle streaming data
- Data manipulations
   - How can we use spark to build proper data pipelines in a datawarehouse. Can it handle scd types or bwts?
- Connection to database
   - How can we connect to database, read, write, update, delete operations
- Spark native
   - Play around how the cores work, change the nodes, partitions etc and see how they change. Generate explain plan using explain and see the execution plan




