# ðŸ“‚ Reading Data with PySpark

---

## ðŸŽ¯ Purpose
This repository demonstrates how to read different file formats (**CSV, Excel, Parquet**) into **PySpark DataFrames**.  
It is designed as a quick reference for data engineers and analysts working with Spark.

---

## âš¡ General Steps

1. **Initiate the Spark session**  
   Create a `SparkSession` which is the entry point for using PySpark.  

2. **Read the file from repo**  
   Load files (CSV, Excel, Parquet) stored in the `data/` directory.  

3. **Read into a Spark DataFrame**  
   Convert the data into a DataFrame and perform basic operations.